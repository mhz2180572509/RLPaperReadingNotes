# Reinforcement Learning Paper Notes

The reading notes of reinforcement learning papers.

## Model-Free RL

### Deep Q-Learning

1. [[DQN] Deep Q-Networks](./Standard%20RL/Model-Free/1-DQN.md)
    * Playing Atari with Deep Reinforcement Learning.
    * Human-level control through deep reinforcement learning.
2. [[DRQN] Deep Recurrent Q-Networks](./Standard%20RL/Model-Free/2-DRQN.md): Deep Recurrent Q-Learning for Partially Observable MDPs.
3. [[DDQN] Double Deep Q-Networks](./Standard%20RL/Model-Free/3-DDQN.md): Deep Reinforcement Learning with Double Q-Learning.


## Hierarchical RL

## Basic Hierarchical RL

1. [Options framework](./Herarchical%20RL/Basic%20HRL/1-options.md): Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning.

### Sub-Goals Discovery

1. [Multiple-instance learning based sub-goals discovery](./Herarchical%20RL/Sub-Goals%20Discovery/1-Multiple-Instance.md): Automatic Discovery of Subgoals in Reinforcement Learning using Diverse Density.
2. [Interaction graph and bewteenness based sub-goals discovery](./Herarchical%20RL/Sub-Goals%20Discovery/2-Betweenness%20Based.md): Skill Characterization Based on Betweenness.
3. [Q-Cut algorithm](./Herarchical%20RL/Sub-Goals%20Discovery/3-Q-Cut.md): Q-Cut - Dynamic Discovery of Sub-goals in Reinforcement Learning.
4. [L-Cut algorithm](./Herarchical%20RL/Sub-Goals%20Discovery/4-L-Cut.md): Identifying Useful Subgoals in Reinforcement Learning by Local Graph Partitioning.
5. [PVFs representation learning based](./Herarchical%20RL/Sub-Goals%20Discovery/5-PVFs.md): A Laplacian Framework for Option Discovery in Reinforcement Learning.
6. [Hierarchical Assignment of Sub-goals to Sub-policies LEarning algorithm (HASSLE)](Herarchical%20RL/Sub-Goals%20Discovery/6-HASSLE.md): Hierarchical Reinforcement Learning with Subpolicies Specializing for Learned Subgoals.
7. [Hierarchical Self-Play algorithm [HSP]](./Herarchical%20RL/Sub-Goals%20Discovery/7-HSP.md): Learning Goal Embeddings via Self-Play for Hierarchical Reinforcement Learning.